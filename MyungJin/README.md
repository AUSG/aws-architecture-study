## AWS - Architecture study: WEB APPLICATION HOSTING

- https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_web_01.pdf

"AWS Architecture 중에서 가장 기초적으로 구현할 수 있는 모델은 어떤 게 있을까?"라는 고민이 있었는데, 이번 스터디를 진행하면서 그 부분을 해결할 수 있었다.

물론, '구현'을 목적으로 한다면, 더 작은 아키텍처를 선정했을테지만, AWS를 제대로 사용하고, 이를 활용하는 수준을 목적으로 한다면 간단하면서도 각 기능이 원활하게 돌아가는 아키텍처를 선정해야 한다는 생각이 있었다. 그래서 이번 스터디를 기회로 AWS 아키텍처 센터에서 기본적으로 제공하는 아키텍처 중 가장 처음 만나볼 수 있는 Web Application Hosting 아키텍처를 구현해보고자 했다.

일단 위 PDF에 나와있는 서비스 중 전에 사용해본 서비스는 Route 53, S3, ELB, EC2, RDS가 있었다. 하지만 이는 아키텍처를 고려하고 설계를 먼저 한 것이 아니라 필요에 의해서 하나하나 만들었을 뿐이었기 때문에 깊이가 부족하다고 느끼고 있어서 이번 기회에 제대로 알아보려 한다. 아자아자!

설계는 아키텍처 센터에서 이미 제공하고 있으니 바로 구현을 해야 할텐데, 구현에 앞서 우선적으로 각 서비스가 어떤 것인지를 알아보는 시간이 필요할 것 같아서 각 서비스에 대해 스터디한 내용을 살짝 공유해보려 한다.

### Amazon Route53

우선 [Amazon Route 53란 무엇입니까?](https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/Welcome.html)를 참고하도록 하자. 해당 참조에 의하면 도메인 등록, DNS 라우팅, 상태 확인의 3가지 주요 기능을 조합하여 실행할 수 있는 서비스라고 한다. 각 요소를 하나하나 살펴보도록 하자.

![dns-routing](assets/dns-routing.png)

- 도메인 등록은 우리가 흔히 알고 있는 것처럼 .com이나 .kr 등의 도메인을 자신만의 이름로 사용할 수 있게 해주는 서비스이다. Ex. https://www.naver.com

- 다음으로 DNS 라우팅은 인터넷 트래픽을 도메인의 리소스로 라우팅하는 것을 말한다. 다시 말해 사용자의 요청이나 입력 등을 등록된 도메인에 전달하는 작업을 말하는 것이다.
  - 더불어 도메인의 형태가 항상 우리가 알고있는 www~로 시작하는 것만 존재하는 것이 아니라는 것에 유의하자. 우리가 흔히 알고있는 www는 World Wide Web의 약지로, 하나의 규격이다. 가령 https://mail.google.com와 같은 도메인의 사용도 가능하다는 것이다.
  - 그렇다면 위와 같이 모든 도메인을 따로 등록해야 할까? 그건 아니다. 가령 구글을 예로 들자면 구글의 모든 서비스를 Route 53을 통해 하나로 라우팅하고 싶다면 도메인 입력 란에 google.com만 입력하는 것도 방법이다. 이때 이를 최상위 도메인이라고 부를 수 있으며 앞선 메일 혹은 홈 페이지를 하위 도메인으로 설정할 수도 있다.
  - DNS에 대한 자세한 내용은 [DNS란 무엇입니까?](https://aws.amazon.com/ko/route53/what-is-dns/)을 활용하도록 하자.

- 마지막으로 상태 확인은 통신되고 있는 리소스의 상태를 확인한다는 의미이다. 문서에 따르면 Route 53은 인터넷을 통해 웹 서버 같은 리소스로 자동화된 요청을 보내어 접근 및 사용이 가능하고, 정상 작동 중인지 확인하는 기능을 한다고 한다. 더불어 리소스를 사용할 수 없게 될 때 알림을 수신한다거나 (비정상 리소스가 아닌) 다른 곳으로 인터넷 트래픽을 라우팅할 수도 있다고 한다.

### Amazon CloudFront(CF)

CloudFront는 사용해보지 않았기 때문에 무척 궁금했다. 그래서 [Amazon CloudFront란?](https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)을 참고하기로 했다. 문서에 따르면 "Amazon CloudFront는 .html, .css, .js 및 이미지 파일과 같은 정적 및 동적 웹 콘텐츠를 사용자에게 더 빨리 배포하도록 지원하는 웹 서비스입니다."라는 설명을 볼 수 있다.

잉? 이런 건 EC2를 통해서 하는 게 아니었나? 가만, 다시 살펴보니 **정적 및 동적 웹 콘텐츠**라는 단어가 신경쓰인다. 그렇구나. 이건 내 웹 사이트의 contents에 해당하는 이야기구나! 그렇다면 소스 코드는 왜 있는 걸까? 조금 더 문서를 읽어보자.

```
CloudFront는 엣지 위치라고 하는 데이터 센터의 전 세계 네트워크를 통해 콘텐츠를 제공합니다. CloudFront를 통해 서비스하는 콘텐츠를 사용자가 요청하면 지연 시간이 가장 낮은 엣지 로케이션으로 라우팅되므로 콘텐츠 전송 성능이 뛰어납니다.

- 콘텐츠가 이미 지연 시간이 가장 낮은 엣지에 있는 경우 CloudFront가 콘텐츠를 즉시 제공합니다.
- 콘텐츠가 엣지 로케이션에 없는 경우 CloudFront는 콘텐츠의 최종 버전에 대한 소스로 지정된 오리진(예: Amazon S3 버킷, MediaPackage 채널, HTTP 서버(예: 웹 서버) 등)에서 콘텐츠를 검색합니다.
```

이 글을 통해 "엣지 로케이션이 contents에 대한 Cache 역할을 하는구나!"라고 이해할 수 있었지만, 그럼에도 왜 EC2에서 할 수 있는 작업을 굳이 CloudFront에서 하는지 몰랐다. 하지만 이런 의문은 다음 문장을 통해 바로 해결할 수 있었다.

```
예를 들어, CloudFront가 아닌 일반적인 웹 서버에서 이미지를 제공한다고 가정합니다. 예를 들어 http://example.com/sunsetphoto.png URL을 사용하여 sunsetphoto.png라는 이미지를 서비스할 수 있습니다.

사용자는 이 URL로 쉽게 이동해 해당 이미지를 볼 수 있습니다. 하지만 이미지가 발견될 때까지 인터넷으로 이루어진 상호 연결된 네트워크의 복잡한 모음을 통해 네트워크에서 다른 네트워크로 요청이 라우팅되었다는 사실은 아마도 모르고 있을 것입니다.
```

이는 리다이렉션을 통해 사용자가 콘텐츠에 접근하게 될 경우 발생하는 비용을 줄이고자 하는 목적으로 사용될 수 있음을 암시하고 있다. 앞서 이해한 Cache의 개념을 조금 확장해 사용자의 입장에서 낮은 지연 시간으로 contents를 얻고, 비용을 절약하게 된다는 것을 이해했다.

이는 언뜻 보기에는 별 것 아닐 수도 있지만, 나에게 있어서는 놀라운 기술일 수밖에 없다. 앞서 언급한 '비용'에는 사용자 경험, 물리 장비, 인력 등 다양한 의미가 포함되어 있고, 이를 단번에 최적화한 기술이기 때문이다. 놀라움도 잠시 다음 문장을 통해서 이해를 다질 수 있었다.

```
CloudFront는 AWS 백본 네트워크를 통해 콘텐츠를 가장 효과적으로 서비스할 수 있는 엣지로 각 사용자 요청을 라우팅하여 콘텐츠 배포 속도를 높입니다. 일반적으로 CloudFront 엣지가 최종 사용자에게 가장 빨리 제공합니다. AWS 네트워크를 사용하면 사용자의 요청이 반드시 통과해야 하는 네트워크의 수가 줄어들어 성능이 향상됩니다. 파일의 첫 바이트를 로드하는 데 걸리는 지연 시간이 줄어들고 데이터 전송 속도가 빨라집니다.

또한 파일(객체라고도 함)의 사본이 전 세계 여러 엣지 로케이션에 유지(또는 캐시)되므로 안정성과 가용성이 향상됩니다.
```

정말 너무 환상적인 서비스군! 저렴한 비용으로 각 도시에 나의 콘를 Caching할 수 있다니.. 그럼 놀라움은 잠시 뒤로 하고 다음 서비스를 알아보자.

### Amazon S3

흔히 우리가 Storage 기능을 한다고 알고있는 S3다. 자세한 설명을 하지 않아도 이미 이해하고 있었지만, 내가 하고 있는 이해는 경험에 의한 것이기 때문에 오늘을 기회로 [Amazon S3란 무엇입니까?](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/Welcome.html)를 읽어보도록 하자.

아무래도 Storage 기능만을 제공하기 때문에 매우 짧다. 그래서 다음의 한 박스로 이를 이해할 수 있겠다.

```
Amazon Simple Storage Service는 인터넷용 스토리지 서비스입니다. 이 서비스는 개발자가 더 쉽게 웹 규모 컴퓨팅 작업을 수행할 수 있도록 설계되었습니다.

Amazon S3에서 제공하는 단순한 웹 서비스 인터페이스를 사용하여 웹에서 언제 어디서나 원하는 양의 데이터를 저장하고 검색할 수 있습니다. 또한 개발자는 Amazon이 자체 웹 사이트의 글로벌 네트워크 운영에 사용하는 것과 같은 높은 확장성과 신뢰성을 갖춘 빠르고 경제적인 데이터 스토리지 인프라에 액세스할 수 있습니다. 이 서비스의 목적은 규모의 이점을 극대화하고 개발자들에게 이러한 이점을 제공하는 것입니다.

이 가이드는 버킷 및 객체와 같은 Amazon S3의 핵심 개념과, Amazon S3 애플리케이션 프로그래밍 인터페이스(API)를 사용하여 이러한 리소스에 대한 작업 방법을 설명합니다.
```

S3는 Storage의 기능을 하며 버킷이라고 부르는 단위를 통해 정적 파일을 관리한다는 것을 이해했다. 더불어 콘솔을 통해 제공되는 인터페이스를 활용하거나 API를 통해 코드에서의 활용도 가능할 것이라는 것을 이해할 수 있었다. 구글 드라이브인데 개발에 활용할 수 있겠다!

### Elastic Load Balancing(ELB)

ELB는 로드 밸런싱이라고 부르는 작업을 해주는 서비스로 이해하고 있다. 이것도 지극히 경험적인 이해이므로 [Elastic Load Balancing란 무엇입니까?](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/userguide/what-is-load-balancing.html)를 통해서 정확하게 이해해보자.

일반적으로 로드 밸런싱이라 하면 트래픽을 분산하기 위해 사용한다고 이해하고 있다. 이에 대한 자세한 내용은 [부하분산](https://ko.wikipedia.org/wiki/%EB%B6%80%ED%95%98%EB%B6%84%EC%82%B0)을 통해 알아보도록 하고 이 글에서는 ELB를 알아보도록 하자. 문서에 따른 설명은 다음과 같다. 부가적으로 트래픽을 분산한다는 의미보다는 정해진 수의 CPU나 메모리같은 컴퓨팅 자원에게 작업을 나눠 제공한다고 이해하는 것이 바람직하겠다.

```
Elastic Load Balancing는 Amazon EC2 인스턴스, 컨테이너 및 IP 주소와 같은 여러 대상에 대해 수신 애플리케이션 또는 네트워크 트래픽을 여러 가용 영역에 배포합니다. 애플리케이션에 대한 트래픽이 시간이 지남에 따라 변경되므로 Elastic Load Balancing가 로드 밸런서를 확장하고 대다수의 워크로드에 맞게 자동으로 조정할 수 있습니다.
```

이를 보고 동적인 부하 분산이 가능하겠다고 생각했다. 가령 어떤 날에는 1의 트래픽이, 어떤 날에는 10의 트래픽이 들어오는 서비스에서 트래픽을 처리하려면 10의 가용량을 항상 가지고 있어야 하기 때문에 1의 트래픽이 들어오는 날에는 9의 자원 낭비가 생길 수 있을 것이다. 그런데 이를 동적으로 관리한다면, 들어오는 트래픽에 따라 가용 공간을 늘려 사용할 수 있을 것이기 때문에, 심지어 위 내용에서 '자동'으로 저장할 수 있기 때문에 자원의 낭비를 최소화할 것이라 생각할 수 있었다.

이런 생각은 문서에서도 나타나고 있다.

```
로드 밸런서 이점

로드 밸런서는 워크로드를 가상 서버와 같은 다수의 컴퓨팅 리소스로 분산합니다. 로드 밸런서를 사용하면 애플리케이션의 가용성과 내결함성이 높아집니다.

애플리케이션에 대한 요청의 전체적인 흐름을 방해하지 않고 필요에 따라 로드 밸런서에서 컴퓨팅 리소스를 추가 및 제거할 수 있습니다.

로드 밸런서가 정상적인 대상에만 요청을 보낼 수 있도록 컴퓨팅 리소스의 상태를 모니터링하는 데 사용되는 상태 확인을 구성할 수 있습니다. 또한 컴퓨팅 리소스가 주요 작업에 집중할 수 있도록 암호화 및 복호화 작업을 로드 밸런서로 오프로드할 수 있습니다.
```

### Amazon EC2

흔히 알고 있는 EC2의 경우에도 [Amazon EC2란 무엇입니까?](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/concepts.html)를 통해 살펴보자.

```
Amazon Elastic Compute Cloud(Amazon EC2)는 Amazon Web Services(AWS) 클라우드에서 확장식 컴퓨팅을 제공합니다. Amazon EC2를 사용하면 하드웨어에 선투자할 필요가 없어 더 빠르게 애플리케이션을 개발하고 배포할 수 있습니다. Amazon EC2를 통해 원하는 만큼 가상 서버를 구축하고 보안 및 네트워크 구성과 스토리지 관리가 가능합니다. 또한 Amazon EC2는 요구 사항이나 갑작스러운 인기 증대 등 변동 사항에 따라 신속하게 규모를 확장하거나 축소할 수 있어 서버 트래픽 예측 필요성이 줄어듭니다.
```

이번 정리를 통해 얻은 큰 수확 중 하나는 기존에 당연하게 사용하던 기술의 기능을 한 번에 정리하게 됐다는 점이다. EC2만 하더라도 가상 컴퓨팅 파워를 제공하는 것 외에도 다음과 같은 디테일한 기능을 가지고 있다는 것을 처음으로 알게되었기 때문이다.

```
Amazon EC2의 기능
Amazon EC2는 다음의 기능을 제공합니다.

- 인스턴스: 가상 컴퓨팅 환경
- Amazon 머신 이미지(AMI): 서버에 필요한 운영체제와 여러 소프트웨어들이 적절히 구성된 상태로 제공되는 템플릿으로 인스턴스를 쉽게 만들 수 있습니다.
- 인스턴스 유형: 인스턴스를 위한 CPU, 메모리, 스토리지, 네트워킹 용량의 여러 가지 구성 제공
- 키 페어를 사용하여 인스턴스 로그인 정보 보호(AWS는 퍼블릭 키를 저장하고 사용자는 개인 키를 안전한 장소에 보관하는 방식)
- 인스턴스 스토어 볼륨: 임시 데이터를 저장하는 스토리지 볼륨으로 인스턴스 종료 시 삭제됨
- Amazon Elastic Block Store(Amazon EBS), 즉 Amazon EBS 볼륨을 사용해 영구 스토리지 볼륨에 데이터 저장
- 인스턴스와 Amazon EBS 볼륨 등의 리소스를 다른 물리적 장소에서 액세스할 수 있는 지역 및 가용 영역
- 보안 그룹을 사용해 인스턴스에 연결할 수 있는 프로토콜, 포트, 소스 IP 범위를 지정하는 방화벽 기능
- 탄력적 IP 주소(EIP): 동적 클라우드 컴퓨팅을 위한 고정 IPv4 주소
- 태그: 사용자가 생성하여 Amazon EC2 리소스에 할당할 수 있는 메타데이터
- AWS 클라우드에서는 논리적으로 격리되어 있지만, 원할 때 마다 고객의 네트워크와 간편히 연결할 수 있는 가상 네트워크, Virtual Private Clouds(VPC)
```

물론 이런 기능들의 디테일을 설정하기 위해서는 보다 많은 스킬업이 필요하겠지만, '가능하다' 정도만 이해하고 넘어가는 것도 나중에 트러블 슈팅, 비용 최적화 등을 위해 큰 도움이 될 것만 같다. 정말 좋다!

추가적으로 따로 단락을 만들어 언급하려 했던 [Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html)을 간단히 소개해보자면, 다음과 같다.

```
Amazon EC2 Auto Scaling를 통해 애플리케이션의 로드를 처리할 수 있는 정확한 수의 Amazon EC2 인스턴스를 보유하도록 보장할 수 있습니다. Auto Scaling 그룹이라는 EC2 인스턴스 모음을 생성합니다. 각 Auto Scaling 그룹의 최소 인스턴스 수를 지정할 수 있으며, Amazon EC2 Auto Scaling에서는 그룹의 크기가 이 값 아래로 내려가지 않습니다. 각 Auto Scaling 그룹의 최대 인스턴스 수를 지정할 수 있으며, Amazon EC2 Auto Scaling에서는 그룹의 크기가 이 값을 넘지 않습니다. 원하는 용량을 지정한 경우 그룹을 생성한 다음에는 언제든지 Amazon EC2 Auto Scaling에서 해당 그룹에서 이만큼의 인스턴스를 보유할 수 있습니다. 조정 정책을 지정했다면 Amazon EC2 Auto Scaling에서는 애플리케이션의 늘어나거나 줄어드는 수요에 따라 인스턴스를 시작하거나 종료할 수 있습니다.
```

Auto Scaling은 규모가 있는 서비스에서 필수적으로 필요할 것이라 생각된다. 왜냐하면 EC2의 인스턴스가 자동으로 스케일을 조정하는 경우는 트래픽이 많지 않으면 필요없을 것이라고 생각하기 때문이다. 하지만 이는 다소 편향된 생각이다. Auto-Scailing을 설정하지 않으면 만약 우리 서비스의 트래픽이 급격하게 증가하는 경우에는 서버가 버티지 못할 것이기 때문이다. 스타트업의 경우라면 만에 하나 있을 '대박'의 기회를 한순간에 놓칠 수도 있을 거라고 생각한다.

최소한의 인스턴스 수를 유지하면서 트래픽이 급격하게 증가할 경우에는 자동적으로 스케일 업을 진행하게 구현한다면 트래픽의 갑작스러운 변화에도 신속히 대응할 수 있을 것이라고 느꼈다. 문서에서는 다음과 같은 예시를 들어 이해를 돕는다.

```
예를 들어, 다음 Auto Scaling 그룹의 경우 최소 인스턴스 수 1개, 희망 인스턴스 용량 2개, 최대 인스턴스 수 4개가 됩니다. 사용자가 정의한 조정 정책에 따라 인스턴스 수가 최소 및 최대 인스턴스 수 내에서 지정하는 조건에 따라 조절됩니다.
```

![auto-scailing](assets/auto-scailing.png)

### Amazon RDS

대망의 마지막 서비스이다! 이 설명이 끝나면 이제 구현이 가능하다! [Amazon Relational Database Service(Amazon RDS)란 무엇입니까?](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Welcome.html)를 살펴보면, RDS를 다음과 같이 설명하고 있다.

```
Amazon Relational Database Service(Amazon RDS)는 클라우드에서 관계형 데이터베이스를 더 쉽게 설치, 운영 및 확장할 수 있는 웹 서비스입니다. 이 서비스는 산업 표준 관계형 데이터베이스를 위한 경제적이고 크기 조절이 가능한 용량을 제공하고 공통 데이터베이스 관리 작업을 관리합니다.
```

일반적인 RDB(Relatinal Database)를 구현하기 위해선 따로 DB 서버를 두거나 하나의 서버에 해당 SQL의 DBMS를 설치해 콘솔 혹은 별도의 GUI 프로그램을 사용해야 했다. 하지만 RDS는 모든 DBMS의 UI를 하나로 통합해 제공하기 때문에 DBMS의 변경, 이주(Migation), 통합(Integration) 등에서 발생하는 정신적 스트레스, 별도의 학습 코스트를 최소화할 수 있을 것이다. 더불어 RDS는 별도의 Database 관리가 없이도 모니터링, 테이블 변경 등의 처리를 할 수 있어 이를 통해 다양한 비용을 절약할 수 있을 것이다.

이러한 필자의 생각은 문서 하단의 설명에서도 나온다.

```
Amazon RDS의 개요

관리되는 관계형 데이터베이스 서비스가 필요한 이유는 무엇일까요? Amazon RDS가 어렵거나 지루한 관계형 데이터베이스 관리 작업을 대다수 대신하기 때문입니다.

- 서버를 구입하면 CPU, 메모리, 스토리지 및 IOPS가 모두 한데 묶여 제공됩니다. Amazon RDS를 사용하면 이 모두가 따로 분할되므로 독립적으로 확장할 수 있습니다. CPU가 더 많이 필요하거나 IOPS가 더 적게 필요하거나 스토리지가 더 많이 필요할 경우 쉽게 할당할 수 있습니다.
- Amazon RDS는 백업, 소프트웨어 패치, 자동 장애 감지 및 복구를 관리합니다.
- 관리형 서비스 환경을 제공하기 위해 Amazon RDS는 DB 인스턴스에 대해 shell 액세스를 제공하지 않으며, 고급 권한을 필요로 하는 특정 시스템 절차와 테이블에 대한 액세스를 제한합니다.
- 필요할 때 자동화된 백업을 수행하거나 고유한 백업 스냅샷을 수동으로 만들 수 있습니다. 이러한 백업을 사용하여 데이터베이스를 복원할 수 있습니다. Amazon RDS 복원 프로세스는 안정적이고 효율적입니다.
- 기본 인스턴스 및 문제 발생 시 장애 조치를 수행할 수 있는 동기식 보조 인스턴스에서 가용성을 높일 수 있습니다. MySQL, MariaDB 또는 PostgreSQL 읽기 전용 복제본을 사용해 읽기 조정을 높일 수도 있습니다.
- 이미 친숙한 MySQL, MariaDB, PostgreSQL, Oracle 및 Microsoft SQL Server 같은 데이터베이스 제품을 사용할 수 있습니다.
- 데이터베이스 패키지의 보안 외에도 AWS Identity and Access Management(IAM)을 사용해 사용자 및 권한을 정의하는 방법으로 RDS 데이터베이스에 액세스할 수 있는 사용자를 제어할 수 있습니다. 데이터베이스를 가상 사설 클라우드에 넣어 데이터베이스를 보호할 수도 있습니다.
```

RDS에는 DB 인스턴스라는 단위가 존재한다. DB 인스턴스는 RDS의 기본 빌딩 블록(최소 단위)라고 할 수 있다. 더불어 DB 인스턴스는 클라우드에 존재하기 때문에 서비스와는 완전히 격리된 데이터베이스 환경이다. 그렇기 때문에 서비스 운영의 호환성을 고려하지 않아도 된다는 장점을 가지고 있다.

지금은 이정도만 이해하고 넘어가도 서비스를 사용함에 문제가 없다. 하지만, 더욱 자세한 설명을 원한다면 위에 제공된 링크를 통해 더욱 깊이 학습하도록 하자.

이제서야 이번 아키텍처에서 사용하는 모든 서비스를 정리할 수 있었다. 하지만, 아직 아키텍처의 전반적인 설명을 하지 않았기 때문에 이를 설명할 필요도 있다고 생각하기 때문에 지금까지의 내용을 정리할 겸 사용자의 흐름에 따라 다음과 같이 요약할 수 있다.

1. 유저는 DNS 응답(requests)를 하나의 고가용성 DNS 서비스인 Amazon Route53에 보낸다. 이때 네트워크 트래픽은 AWS에서 실행되는 인프라(Infrastructure)로 라우팅된다.
2. 정적, 동적, 실시간 콘텐츠는 하나의 글로벌 엣지 로케이션(일종의 Conetns Cache) 네트워크인 CloudFront에 의해 전달된다. 이때 응답(requests)은 자동적으로 가장 가까운 엣지 로케이션으로 라우팅되고, 그래서 콘텐츠는 최적의 가용성을 가지고 전달된다.
3. 자원(Resources)과 정적 콘텐츠는 미션 크리티컬 및 기본 데이터 스토리지를 위해 고안된 내구성이 뛰어난 스토리지 인프라인 S3 위에 적재된(stored) 웹 어플리케이션에 의해 사용된다.
4. HTTP 응답은 우선적으로 가용 영역(AZs)에서 다수의 Amazon Elastic Compute Cloud(EC2) 인스턴스로 들어오는 애플리케이션 트래픽을 자동으로 배분하는 ELB에 의해 처리(handled)되어진다.
5. 웹 서버와 애플리케이션 서버는 EC2 위에서 배포되어진다. 여기서 대부분의 조직은 AMI(Amazon Machine Image)를 선택한 다음 필요에 맞게 사용자 정의합니다. 이 사용자 정의된(custom) AMI는 앞으로의 웹 개발의 출발점이 될 것이다.
6. 웹 서버와 애플리케이션 서버는 Auto Scailing 그룹 안에서 배포되어진다. 이때 Auto Scaling은 정의한 조건에 따라 자동으로 용량을 늘리거나 줄이면서 조절합니다. Auto Scailing 기능을 사용하면 성능을 유지하기 위해 요구 사항이 급증 할 때 사용중인 EC2의 인스턴스의 수가 무사히 증가하고, 요구 사항이 발생하면 자동적으로 감소하여 비용을 최소화 할 수 있습니다.
7. 고가용성을 제공하기 위해 어플리케이션 데이터가 포함된 관계형 데이터베이스는 RDS의 다중 가용구역(Multi-AZ, Master-Slave) 배포 위에서 중복적으로(redundantly) 호스팅된다.

드디어 실습을 위한 사전 학습이 마무리됐다. 이 글 이후에는 실습을 위한 자료를 제공해 보다 나은 학습을 진행하고자 한다.

[다음 글(실습)](./training.md)
